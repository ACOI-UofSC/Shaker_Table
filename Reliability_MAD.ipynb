{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aa5a048",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import xlrd\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import math\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed73d619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mad(some_data):\n",
    "    some_data = some_data.loc[:, ['Time', 'X', 'Y', 'Z', 'Magnitude']].dropna()\n",
    "    all_mad = {}\n",
    "    time_name = \"Time\"\n",
    "        \n",
    "    # Grab the first timestamp from data\n",
    "    # print(some_data.shape)\n",
    "    start = some_data.loc[some_data.index[0], time_name]\n",
    "    # Specify the amount of time to aggregate over\n",
    "    agg_len = 5\n",
    "    # Grab end of aggregation period\n",
    "    end_time = start + timedelta(seconds=agg_len - 1)\n",
    "    # print(f\"Start Time {start} \\nEnd Time {end_time}\")\n",
    "    # Calculate the total length of the trial in seconds\n",
    "    trial_length = (some_data.loc[some_data.index[-1], time_name] - start).total_seconds()\n",
    "    # Runs the total length of trial divided by the length of time we aggregate over\n",
    "    # essentialy creates a window of agg_len, and interval of agg_len\n",
    "    for i in range(int(trial_length//agg_len)):\n",
    "        # print(end_time)\n",
    "        # Get agg_len seconds worth of accelerometer readings\n",
    "        group_s = some_data.loc[(some_data[time_name] >= start) & (some_data[time_name] <= end_time), :]\n",
    "        # print(group_s)\n",
    "        # Get the mean X, Y, and Z of those readings\n",
    "        agg_s = group_s.aggregate(lambda x : np.mean(x))\n",
    "        # print(agg_s)\n",
    "        mag_s = agg_s[4]\n",
    "\n",
    "        # print(f\"{mag_s}\")\n",
    "        # Subtract the mean magnitude from each accelerometer magnitude from each vector magnitude and then take abs\n",
    "        dif_mean = group_s['Magnitude'].apply(lambda x : abs(x - mag_s))\n",
    "        # Caclulate the sum of all the vector mags - mean mags. Then divide by the number of vectors\n",
    "        # print(dif_mean.sum())\n",
    "        # print(f\"Shape of division {dif_mean.shape[0]}\")\n",
    "        # print(dif_mean.shape[0])\n",
    "        mad = (dif_mean.sum()) / dif_mean.shape[0]\n",
    "\n",
    "        # print(mad)\n",
    "\n",
    "        # Add each Mad and the corresponding time to a list :\n",
    "        all_mad[end_time] = mad\n",
    "        # \n",
    "        start = end_time + timedelta(seconds=1)\n",
    "        end_time = start + timedelta(seconds=agg_len - 1)\n",
    "        \n",
    "\n",
    "    mad_df = pd.Series(data=all_mad, name=\"MAD\")\n",
    "    return mad_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "57555525",
   "metadata": {},
   "outputs": [],
   "source": [
    "align_path = \"V:\\\\R01 - W4K\\\\2_Shaker project\\\\Devices Evaluated\\\\Reliability\\\\Processed Data\\\\Round 2\\\\Apple\\\\Trials\\\\\"\n",
    "# align_path = \"V:\\\\R01 - W4K\\\\2_Shaker project\\\\Devices Evaluated\\\\Reliability\\\\Processed Data\\\\Round 2\\\\Actigraph\\\\Trials\\\\\"\n",
    "# align_path = \"V:\\\\R01 - W4K\\\\2_Shaker project\\\\Devices Evaluated\\\\Reliability\\\\Processed Data\\\\Round 2\\\\Garmin\\\\Trials\\\\\"\n",
    "# align_path = \"V:\\\\R01 - W4K\\\\2_Shaker project\\\\Devices Evaluated\\\\BlackAccelerometerTest\\\\Processed Data\\\\Trials\\\\\"\n",
    "aligned_files = glob.glob(align_path + \"Trial [0-9][0-9]*\")\n",
    "agg_files = glob.glob(align_path + \"*Agg*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "011df71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for align, agg in zip(aligned_files, agg_files):\n",
    "    # Read in aligned data\n",
    "    align_data = pd.read_csv(align, parse_dates=['Time'], infer_datetime_format=True)\n",
    "    \n",
    "    # Break data up by device id. Then calculate MAD\n",
    "    ids = align_data['ID'].unique()\n",
    "    mad = None\n",
    "    for device in ids:\n",
    "        id_mad = calc_mad(align_data.loc[(align_data['ID'] == device), ['Time', 'X','Y','Z','Magnitude']])\n",
    "        id_mad = id_mad.to_frame()\n",
    "        id_mad.insert(0, \"ID\", device)\n",
    "        if mad is None :\n",
    "            mad = id_mad\n",
    "        else :\n",
    "            mad = pd.concat([mad, id_mad])\n",
    "    old_agg = pd.read_csv(agg, parse_dates=['Time'], infer_datetime_format=True)\n",
    "    new_agg = old_agg.merge(mad, how='left', left_on=['Time', 'ID'], right_on=[mad.index, 'ID'])\n",
    "    new_agg.to_csv(agg[:-4] + \"_v2.csv\", index=None)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dcb28441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate new files\n",
    "agg_v2_files = glob.glob(align_path + \"*v2.csv\")\n",
    "data = None\n",
    "for file in agg_v2_files:\n",
    "    temp = pd.read_csv(file)\n",
    "    if data is None :\n",
    "        data = temp\n",
    "    else :\n",
    "        data = pd.concat([data,temp])\n",
    "data.to_csv(align_path + \"Aggregated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a80e11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
